<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<style>
div.ml1 {
  margin-left: 30px;
}
ul.a {list-style-type: circle;}
ul.b {list-style-type: square;}
ul.c {list-style-type: square;}
</style>
<html>
	<head>
		<title>Challenge-Task1 Software</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">

					<!-- Logo -->
					<!-- <img src="images/isca.png" width="6%" height="6%" style="margin:0 77% 0 0;"> -->
					<!-- <h1 style="font-size: 120%;  margin: -4% 0 -2% 0"><a href="index.html" id="logo">Multimodal Information
							Based Speech Processing (MISP) Challenge 2022</a></h1> -->
					<h1 style="font-size: 120%;  margin: -1% 0% -1% 0%;"><a href="index.html" id="logo">Multimodal Information
								Based Speech Processing (MISP) 2023 Challenge</a></h1> 	
					<img src="images/ieee.svg" width="7%"height="7%" style="margin:-10% 0% 3% 79%;">
					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li><a href="overview.html">Overview</a></li>
								<li><a href="data.html">Data</a></li>
								<li class="current">
									<a href="#">Task</a>
									<ul>
										<li><a href="task1_instructions.html">Instructions</a></li>										
										<li><a href="task1_software.html">Baseline</a></li>
						                <li><a href="task1_submission.html">Submission</a></li>
									</ul>
								</li>
								
								<!-- <li>
									<a href="#">Task3</a>
									<ul>
										<li><a href="task3_instructions.html">Instructions</a></li>
										<li><a href="task3_data.html">Data</a></li>
										<li><a href="task3_software.html">Software</a></li>
										<li><a href="task3_submission.html">Submission</a></li>
									</ul>
								</li> -->
								<li><a href="download.html">Registration</a></li>
								<li><a href="extral_data.html">Extra Data</a></li>
								<!-- <li><a href="results.html">Results</a></li> -->
								<!-- <li><a href="contact.html">Contact</a></li> -->
							</ul>
						</nav>

				</div>

			<!-- Main -->
			<!-- <h1 style="font-size: 150%;">For details, please refer to Github  <a href="https://github.com/mispchallenge/MISP-2023-Challenge-Baseline">link</a>. The webpage is being updated.</h1> -->
			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">Baseline</h1>
					</header>
					<p>For the code and guide of the baseline system, please refer to <a href="https://github.com/mispchallenge/MISP-2023-Challenge-Baseline">Github link</a></p>
					<p>For more description of the baseline system, please refer to the following two papers:</p>
					<ul>
						<li><a href="https://arxiv.org/abs/2309.08348">The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction</a></li>
						<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608021002355">Correlating subword articulation with lip shapes for embedding aware audio-visual speech enhancement. </a></li>
					</ul>
				</div>
			</section>
			
			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">Data Preparation</h1>
					</header>
					<p>As shown in the Data section, we performed data cleaning on the raw audio data and simulated 6-channel far-field audio using the cleaned near-field speech.</p>
				</div>
			</section>

			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">System Architecture</h1>
					</header>
					<center>
						<figure style="padding:0px;border:0px; margin:10px">
						<img src="images/basline_sys.png" alt="Real Shot" style="width:40%;padding:0px;border:0" />
						<figcaption>Fig.1. Diagram of the baseline system.</figcaption>
						</figure>
					</center>
					<p>As shown in Figure 1, first, we used the oracle diarization results to conduct guided source separation (GSS) on 6-channels mixture audio to initially mitigate the impact of the overlapping speech. Then, we use our recent work - the multimodal embedding aware speech enhancement (MEASE) model to futher extract the speech of the target speaker. The MEASE model comprises a multimodal embedding extractor (in red dashed box) and an embedding-aware enhancement network. For more details, please refer to the two papers above.</p>
				</div>
			</section>

			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">Training Process</h1>
					</header>
					<center>
						<figure style="padding:0px;border:0px; margin:10px">
						<img src="images/two_stage.png" alt="Real Shot" style="width:50%;padding:0px;border:0" />
						<figcaption>Fig.2. The two-stage training process of the baseline system.</figcaption>
						</figure>
					</center>
					<p>As shown in Figure 2, the training process of the baseline system encompasses two stages. Firstly, we trained the MEASE model using the simulated data with MSE as the loss function. In the second stage, we fine-tuned the pre-trained MEASE model using the recognition back-end. Furthermore, to mitigate the issue of mismatch between simulated data and real-world scenarios, we utilized the real far-field data from the training set in the second stage. Because we require that the parameters of the back-end system cannot be changed, we freeze the recognition model and only use the loss returned by it.</p>
				</div>
			</section>

			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">Back-end ASR Testing</h1>
					</header>
					<center>
						<figure style="padding:0px;border:0px; margin:10px">
						<img src="images/back_end_asr.png" alt="Real Shot" style="width:25%;padding:0px;border:0" />
						<figcaption>Fig. 3. Back-end ASR model.</figcaption>
						</figure>
					</center>
					<p>The backend ASR model is based on this following paper:</p>
					<p><a href="https://ieeexplore.ieee.org/abstract/document/10219701">Improving Audio-Visual Speech Recognition by Lip-Subword Correlation Based Visual Pre-training and Cross-Modal Fusion Encoder.</a></p>
					<p>We have given the code and the pre-trained parameters for the ASR model, which you can find in the github link above. You can test the extracted speech directly. In addition, you can also use different methods to use the back-end system to finetune the front-end AVTSE system just like the baseline system, but you must ensure that the back-end system parameters do not change.</p>
				</div>
			</section>

			<section class="wrapper style1">
				<div class="container">
					<header>
						<h1 style="font-size: 150%;">Baseline Results</h1>
					</header>
					<center>
						<figure style="padding:0px;border:0px; margin:10px">
						<figcaption>Tab. 1. Detailed CER (%) and DNSMOS results of different front-end systems on the development set.</figcaption>
						<img src="images/base_results.png" alt="Real Shot" style="width:70%;padding:0px;border:0" />
						</figure>
					</center>
					<p>Table 1 shows the results of different front-end systems in the speech recognition evaluation metric and DNSMOS P.835. It is worth noting that we only use the recognition results as the evaluation indicators. DNSMOS is only used as a reference to study changes in speech quality. The final baseline result is the CER of 26.3. The baseline results of the evaluation set will be given after the evaluation set is released.</p>
					
				</div>
			</section>
			
			
			<!-- Footer -->
				<div id="footer">
					<!-- Copyright -->
						<div class="copyright">
							<ul class="menu">
								<li>&copy; All rights reserved</li><li>E-mail: mispchallenge@gmail.com</li>
							</ul>
						</div>

				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
